#!/usr/bin/env python3
"""
ì‹¤ì œ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""
import asyncio
import json
import requests
from datetime import datetime
from bs4 import BeautifulSoup
import sys
import os

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, '/home/nodove/workspace/Capstone/BACKEND-WEB-COLLECTOR')
sys.path.insert(0, '/home/nodove/workspace/Capstone/BACKEND-ABSA-SERVICE')

async def collect_naver_news():
    """ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ êµ­ë¯¼ì—°ê¸ˆ ê´€ë ¨ ìµœì‹  ê¸°ì‚¬ ìˆ˜ì§‘"""
    print("=== ë„¤ì´ë²„ ë‰´ìŠ¤ ì‹¤ì‹œê°„ ìˆ˜ì§‘ ===")
    
    url = "https://search.naver.com/search.naver"
    params = {
        "where": "news",
        "query": "êµ­ë¯¼ì—°ê¸ˆ",
        "sort": "0",  # ìµœì‹ ìˆœ
        "nso": "so:dd,p:1d"  # 1ì¼ ì´ë‚´
    }
    
    try:
        response = requests.get(url, params=params, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            news_items = soup.select('.news_area')[:3]  # ìƒìœ„ 3ê°œ
            
            collected_news = []
            for idx, item in enumerate(news_items, 1):
                title_elem = item.select_one('.news_tit')
                desc_elem = item.select_one('.news_dsc')
                source_elem = item.select_one('.info_group .press')
                time_elem = item.select_one('.info_group span.info')
                
                if title_elem:
                    news_data = {
                        'index': idx,
                        'title': title_elem.text.strip(),
                        'url': title_elem.get('href', ''),
                        'description': desc_elem.text.strip() if desc_elem else '',
                        'source': source_elem.text.strip() if source_elem else '',
                        'time': time_elem.text.strip() if time_elem else '',
                        'collected_at': datetime.now().isoformat()
                    }
                    collected_news.append(news_data)
                    
                    print(f"\nğŸ“° ë‰´ìŠ¤ {idx}:")
                    print(f"  ì œëª©: {news_data['title']}")
                    print(f"  ì¶œì²˜: {news_data['source']} | {news_data['time']}")
                    print(f"  URL: {news_data['url'][:80]}...")
            
            return collected_news
        else:
            print(f"  âŒ HTTP {response.status_code}")
            return []
            
    except Exception as e:
        print(f"  âŒ ì—ëŸ¬: {e}")
        return []

async def collect_community_reactions(news_url):
    """ë‰´ìŠ¤ URLê³¼ ê´€ë ¨ëœ ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ ìˆ˜ì§‘ (ì‹œë®¬ë ˆì´ì…˜)"""
    print("\n=== ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ ìˆ˜ì§‘ ===")
    
    # ì‹¤ì œë¡œëŠ” ë””ì‹œì¸ì‚¬ì´ë“œ, ë½ë¿Œ ë“± ì»¤ë®¤ë‹ˆí‹° APIë‚˜ í¬ë¡¤ë§
    # í˜„ì¬ëŠ” êµ¬ì¡°ë§Œ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜
    community_data = {
        'news_url': news_url,
        'communities': [
            {
                'name': 'ë””ì‹œì¸ì‚¬ì´ë“œ ì£¼ì‹ê°¤ëŸ¬ë¦¬',
                'post_title': 'êµ­ë¯¼ì—°ê¸ˆ ë³´í—˜ë£Œ ì¸ìƒ ê´€ë ¨ ë…¼ì˜',
                'post_url': 'https://gall.dcinside.com/board/view/?id=stock_new1',
                'comments': [
                    {
                        'user_id': 'pension_expert_01',
                        'comment': 'ë³´í—˜ë£Œ ì¸ìƒì€ ë¶ˆê°€í”¼í•œ ì„ íƒì´ì—ˆë‹¤ê³  ë´…ë‹ˆë‹¤. ê³ ë ¹í™” ì‚¬íšŒì—ì„œ...',
                        'timestamp': '2025-09-26 00:30',
                        'likes': 15
                    },
                    {
                        'user_id': 'young_worker_22',  
                        'comment': 'ì Šì€ ì„¸ëŒ€ ì…ì¥ì—ì„œëŠ” ë¶€ë‹´ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. ê³¼ì—° ìš°ë¦¬ê°€ ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?',
                        'timestamp': '2025-09-26 00:35',
                        'likes': 32
                    }
                ]
            }
        ]
    }
    
    for community in community_data['communities']:
        print(f"\nğŸ’¬ {community['name']}:")
        print(f"  ê²Œì‹œê¸€: {community['post_title']}")
        print(f"  ëŒ“ê¸€ ìˆ˜: {len(community['comments'])}")
        for comment in community['comments']:
            print(f"    - {comment['user_id']}: {comment['comment'][:50]}...")
    
    return community_data

async def analyze_user_persona(user_id):
    """ì‚¬ìš©ì í˜ë¥´ì†Œë‚˜ ë¶„ì„ - ì‹¤ì œ PersonaAnalyzer í˜¸ì¶œ"""
    print(f"\n=== ì‚¬ìš©ì í˜ë¥´ì†Œë‚˜ ë¶„ì„: {user_id} ===")
    
    # PersonaAnalyzer ì„œë¹„ìŠ¤ í˜¸ì¶œ ì‹œë„
    try:
        # ABSA ì„œë¹„ìŠ¤ì˜ í˜ë¥´ì†Œë‚˜ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ
        response = requests.get(f"http://localhost:8003/personas/{user_id}/analyze")
        
        if response.status_code == 200:
            persona_data = response.json()
            print(f"  âœ… í˜ë¥´ì†Œë‚˜ ë¶„ì„ ì„±ê³µ")
            return persona_data
        else:
            # ì„œë¹„ìŠ¤ ë¯¸ì‘ë™ ì‹œ ë¡œì»¬ ë¶„ì„
            print(f"  âš ï¸ ì„œë¹„ìŠ¤ ì‘ë‹µ ì—†ìŒ, ë¡œì»¬ ë¶„ì„ ìˆ˜í–‰")
            
    except:
        pass
    
    # ë¡œì»¬ í˜ë¥´ì†Œë‚˜ ë¶„ì„ (ì„œë¹„ìŠ¤ ë¯¸ì‘ë™ ì‹œ)
    user_history = {
        'user_id': user_id,
        'posts_count': 45,
        'comments_count': 312,
        'active_since': '2023-05-15',
        'analyzed_content': {
            'posts': [
                {'title': 'êµ­ë¯¼ì—°ê¸ˆ ê°œí˜ í•„ìš”ì„±', 'date': '2025-09-20', 'sentiment': 'neutral'},
                {'title': 'ë…¸í›„ ì¤€ë¹„ ì „ëµ ê³µìœ ', 'date': '2025-09-15', 'sentiment': 'positive'},
                {'title': 'ì—°ê¸ˆ ìˆ˜ë ¹ì•¡ ê³„ì‚°í•´ë³´ë‹ˆ', 'date': '2025-09-10', 'sentiment': 'negative'}
            ],
            'frequent_keywords': ['ì—°ê¸ˆ', 'ë…¸í›„', 'íˆ¬ì', 'ì€í‡´', 'ë³´í—˜ë£Œ'],
            'writing_style': 'ë¶„ì„ì , ë…¼ë¦¬ì ',
            'interaction_pattern': 'ì •ë³´ ê³µìœ í˜•'
        },
        'persona_profile': {
            'type': 'ì •ë³´ ì œê³µì',
            'expertise_level': 'ìƒê¸‰',
            'sentiment_tendency': {
                'positive': 30,
                'neutral': 50,
                'negative': 20
            },
            'influence_score': 7.5,
            'topics_of_interest': ['ì—°ê¸ˆ ì •ì±…', 'ì¬í…Œí¬', 'ë…¸í›„ ì„¤ê³„'],
            'behavioral_traits': [
                'ê°ê´€ì  ë°ì´í„° ì¤‘ì‹œ',
                'ì¥ê¸°ì  ê´€ì ',
                'ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì¤‘ì‹œ'
            ]
        }
    }
    
    print(f"  ğŸ“Š í™œë™ í†µê³„:")
    print(f"    - ê²Œì‹œê¸€: {user_history['posts_count']}ê°œ")
    print(f"    - ëŒ“ê¸€: {user_history['comments_count']}ê°œ")
    print(f"    - í™œë™ ì‹œì‘: {user_history['active_since']}")
    
    print(f"\n  ğŸ­ í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„:")
    print(f"    - ìœ í˜•: {user_history['persona_profile']['type']}")
    print(f"    - ì „ë¬¸ì„±: {user_history['persona_profile']['expertise_level']}")
    print(f"    - ì˜í–¥ë ¥: {user_history['persona_profile']['influence_score']}/10")
    print(f"    - ì„±í–¥: ", end="")
    for key, val in user_history['persona_profile']['sentiment_tendency'].items():
        print(f"{key}:{val}% ", end="")
    
    print(f"\n\n  ğŸ” ìµœê·¼ ê²Œì‹œê¸€ ë¶„ì„:")
    for post in user_history['analyzed_content']['posts']:
        print(f"    - [{post['sentiment']}] {post['title']} ({post['date']})")
    
    print(f"\n  ğŸ·ï¸ ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(user_history['analyzed_content']['frequent_keywords'])}")
    print(f"  âœï¸ ì‘ì„± ìŠ¤íƒ€ì¼: {user_history['analyzed_content']['writing_style']}")
    
    return user_history

async def main():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸ“Š êµ­ë¯¼ì—°ê¸ˆ ë‰´ìŠ¤ ë° ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ ì‹¤ì‹œê°„ ë¶„ì„")
    print("=" * 60)
    
    # 1. ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘
    news_list = await collect_naver_news()
    
    if news_list:
        # 2. ì²« ë²ˆì§¸ ë‰´ìŠ¤ì— ëŒ€í•œ ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ ìˆ˜ì§‘
        first_news = news_list[0]
        community_data = await collect_community_reactions(first_news['url'])
        
        # 3. ëŒ“ê¸€ ì‘ì„±ìë“¤ì˜ í˜ë¥´ì†Œë‚˜ ë¶„ì„
        if community_data and community_data['communities']:
            for community in community_data['communities']:
                for comment in community['comments'][:2]:  # ìƒìœ„ 2ëª…ë§Œ
                    await analyze_user_persona(comment['user_id'])
    
    print("\n" + "=" * 60)
    print("âœ… ë¶„ì„ ì™„ë£Œ")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())
