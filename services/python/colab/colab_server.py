 # -*- coding: utf-8 -*-
"""
Google Colab Sentiment Analysis Server
ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Google Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
1. Google Colabì—ì„œ ìƒˆ ë…¸íŠ¸ë¶ì„ ì—½ë‹ˆë‹¤.
2. ì´ íŒŒì¼ì˜ ë‚´ìš©ì„ ì½”ë“œ ì…€ì— ë³µì‚¬í•©ë‹ˆë‹¤.
3. ëŸ°íƒ€ì„ ìœ í˜•ì„ GPUë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤ (í•„ìˆ˜ëŠ” ì•„ë‹˜).
4. ì‹¤í–‰í•©ë‹ˆë‹¤.

í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (Colab ì…€ì—ì„œ ì‹¤í–‰ ì‹œ ì£¼ì„ í•´ì œ í•„ìš”):
!pip install fastapi uvicorn pyngrok transformers torch pydantic nest-asyncio
"""

import os
import sys
import threading
import uvicorn
from fastapi import FastAPI, HTTPException, Header, Depends, Request, BackgroundTasks
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
from pyngrok import ngrok
from transformers import pipeline
import nest_asyncio
import requests
import time

# Colabì˜ ì´ë²¤íŠ¸ ë£¨í”„ ë¬¸ì œ í•´ê²°
nest_asyncio.apply()

# ==========================================
# ì„¤ì • ë° ìƒìˆ˜
# ==========================================
API_KEY = "viki-colab-secret"  # ë³´ì•ˆì„ ìœ„í•œ API í‚¤
PORT = 8000

# ==========================================
# FastAPI ì•± ì´ˆê¸°í™”
# ==========================================
app = FastAPI(
    title="Colab Sentiment Analysis API",
    description="Google Colabì—ì„œ ì‹¤í–‰ë˜ëŠ” ê°ì„± ë¶„ì„ ë° ABSA ì„œë²„",
    version="1.0.0"
)

# ==========================================
# ëª¨ë¸ ë¡œë“œ (ì „ì—­ ë³€ìˆ˜)
# ==========================================
print("ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")

try:
    # 1. ì¼ë°˜ ê°ì„± ë¶„ì„ ëª¨ë¸ (Sentiment Analysis)
    # distilbert-base-uncased-finetuned-sst-2-english: ë¹ ë¥´ê³  ì„±ëŠ¥ ì¤€ìˆ˜
    sentiment_pipeline = pipeline(
        "sentiment-analysis",
        model="distilbert-base-uncased-finetuned-sst-2-english"
    )
    print("âœ… ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # 2. ì†ì„± ê¸°ë°˜ ê°ì„± ë¶„ì„ (ABSA)ì„ ìœ„í•œ Zero-shot Classification ëª¨ë¸
    # facebook/bart-large-mnli: Zero-shot ë¶„ë¥˜ì— ê°•ë ¥í•¨
    # ì‚¬ìš©ë²•: í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ "The sentiment for [Aspect] is [Label]" í˜•íƒœì˜ ê°€ì„¤ì„ ê²€ì¦
    absa_pipeline = pipeline(
        "zero-shot-classification",
        model="facebook/bart-large-mnli"
    )
    print("âœ… ABSA(Zero-shot) ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    sys.exit(1)

# ==========================================
# ë°ì´í„° ëª¨ë¸ (Pydantic)
# ==========================================
class SentimentRequest(BaseModel):
    text: str

class SentimentResponse(BaseModel):
    label: str
    score: float

class AbsaRequest(BaseModel):
    text: str
    aspects: List[str]

class AspectSentiment(BaseModel):
    aspect: str
    label: str
    score: float

class AbsaResponse(BaseModel):
    results: List[AspectSentiment]


class TrainRequest(BaseModel):
    jobId: str
    taskType: str
    callbackUrl: str
    hyperparameters: Dict[str, Any] = {}
    dataset: Optional[Dict[str, Any]] = None
    datasetUrl: Optional[str, Any] = None

# ==========================================
# ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´ / ì˜ì¡´ì„±
# ==========================================
async def verify_api_key(x_api_key: str = Header(...)):
    if x_api_key != API_KEY:
        raise HTTPException(status_code=403, detail="Invalid API Key")
    return x_api_key

# ==========================================
# API ì—”ë“œí¬ì¸íŠ¸
# ==========================================

@app.get("/")
def read_root():
    return {"message": "Colab Sentiment Analysis Server is running. Use POST /sentiment or /absa."}

@app.post("/sentiment", response_model=SentimentResponse, dependencies=[Depends(verify_api_key)])
async def analyze_sentiment(request: SentimentRequest):
    """
    ë‹¨ì¼ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ê°ì„± ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    try:
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ ì²˜ë¦¬ (ëª¨ë¸ì˜ ìµœëŒ€ í† í° ìˆ˜ ê³ ë ¤, ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì˜ˆì™¸ì²˜ë¦¬)
        if not request.text.strip():
            raise HTTPException(status_code=400, detail="Text cannot be empty")

        result = sentiment_pipeline(request.text)[0]
        
        # ê²°ê³¼ í˜•ì‹: {'label': 'POSITIVE', 'score': 0.99...}
        return SentimentResponse(
            label=result['label'],
            score=result['score']
        )
    except Exception as e:
        print(f"Error in /sentiment: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/absa", response_model=AbsaResponse, dependencies=[Depends(verify_api_key)])
async def analyze_absa(request: AbsaRequest):
    """
    í…ìŠ¤íŠ¸ì™€ ì†ì„±(Aspect) ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ê° ì†ì„±ë³„ ê°ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    Zero-shot classificationì„ í™œìš©í•˜ì—¬ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.
    """
    try:
        if not request.text.strip():
            raise HTTPException(status_code=400, detail="Text cannot be empty")
        if not request.aspects:
            raise HTTPException(status_code=400, detail="Aspects list cannot be empty")

        results = []
        candidate_labels = ["positive", "negative", "neutral"]

        for aspect in request.aspects:
            # ê°€ì„¤ í…œí”Œë¦¿ ì„¤ì •: "The sentiment for {aspect} is {}."
            hypothesis_template = f"The sentiment for {aspect} is {{}}."
            
            # Zero-shot classification ì‹¤í–‰
            output = absa_pipeline(
                request.text,
                candidate_labels,
                hypothesis_template=hypothesis_template,
                multi_label=False
            )
            
            # output í˜•ì‹:
            # {
            #   'sequence': '...',
            #   'labels': ['positive', 'neutral', 'negative'],
            #   'scores': [0.9, 0.05, 0.05]
            # }
            
            top_label = output['labels'][0]
            top_score = output['scores'][0]

            results.append(AspectSentiment(
                aspect=aspect,
                label=top_label.upper(),
                score=top_score
            ))

        return AbsaResponse(results=results)

    except Exception as e:
        print(f"Error in /absa: {e}")
        raise HTTPException(status_code=500, detail=str(e))


def run_training_job(req: TrainRequest):
    """ì˜¤ë˜ ê±¸ë¦¬ëŠ” í•™ìŠµ ì‘ì—…ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰í•˜ê³  Java ì„œë²„ë¡œ ì½œë°±ì„ ë³´ëƒ…ë‹ˆë‹¤.

    í˜„ì¬ëŠ” SENTIMENT íƒœìŠ¤í¬ì— ëŒ€í•´ HuggingFace Trainerë¥¼ ì‚¬ìš©í•œ
    ê°„ë‹¨í•œ íŒŒì¸íŠœë‹ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ABSA íƒœìŠ¤í¬ì˜ ê²½ìš°ì—ëŠ”
    í–¥í›„ í™•ì¥ì„ ìœ„í•´ ë¶„ê¸°ë§Œ ì •ì˜í•´ë‘ì—ˆìŠµë‹ˆë‹¤.
    """
    try:
        print(f"[TRAIN] jobId={req.jobId}, taskType={req.taskType} - training started")

        if req.taskType.upper() == "SENTIMENT":
            # ================================
            # 1) ë°ì´í„°ì…‹ ì¤€ë¹„ (Light mode ê¸°ì¤€)
            # ================================
            from datasets import Dataset
            from transformers import (
                AutoTokenizer,
                AutoModelForSequenceClassification,
                TrainingArguments,
                Trainer,
            )
            import numpy as np
            from sklearn.metrics import accuracy_score, f1_score

            examples = []
            if req.dataset and "examples" in req.dataset:
                examples = req.dataset["examples"]

            if not examples:
                raise ValueError("No training examples provided in dataset.examples")

            texts = [ex["text"] for ex in examples]
            labels = [ex["label"] for ex in examples]

            label2id = {"negative": 0, "neutral": 1, "positive": 2}
            id2label = {v: k for k, v in label2id.items()}

            # ë¼ë²¨ì´ ì‚¬ì „ì— ì—†ëŠ” ê²½ìš° ê¸°ë³¸ neutral ë¡œ ë§¤í•‘
            encoded_labels = [label2id.get(l, 1) for l in labels]

            ds = Dataset.from_dict({"text": texts, "label": encoded_labels})

            # ================================
            # 2) í† í¬ë‚˜ì´ì € / ëª¨ë¸ ë¡œë“œ
            # ================================
            base_model_name = req.hyperparameters.get(
                "base_model", "distilbert-base-uncased"
            )
            tokenizer = AutoTokenizer.from_pretrained(base_model_name)
            model = AutoModelForSequenceClassification.from_pretrained(
                base_model_name,
                num_labels=len(label2id),
                id2label=id2label,
                label2id=label2id,
            )

            def preprocess(batch):
                return tokenizer(
                    batch["text"],
                    truncation=True,
                    padding="max_length",
                    max_length=256,
                )

            tokenized = ds.map(preprocess, batched=True)
            split = tokenized.train_test_split(test_size=0.1)
            train_ds = split["train"]
            eval_ds = split["test"]

            # ================================
            # 3) Trainer ì„¤ì • ë° í•™ìŠµ
            # ================================
            output_dir = f"./models/{req.taskType.lower()}/{req.jobId}"
            args = TrainingArguments(
                output_dir=output_dir,
                num_train_epochs=req.hyperparameters.get("epochs", 3),
                per_device_train_batch_size=req.hyperparameters.get("batch_size", 16),
                per_device_eval_batch_size=32,
                learning_rate=req.hyperparameters.get("learning_rate", 5e-5),
                evaluation_strategy="epoch",
                logging_steps=50,
                save_strategy="epoch",
                load_best_model_at_end=True,
            )

            def compute_metrics(eval_pred):
                logits, labels = eval_pred
                preds = np.argmax(logits, axis=-1)
                return {
                    "accuracy": accuracy_score(labels, preds),
                    "f1": f1_score(labels, preds, average="macro"),
                }

            trainer = Trainer(
                model=model,
                args=args,
                train_dataset=train_ds,
                eval_dataset=eval_ds,
                compute_metrics=compute_metrics,
            )

            trainer.train()
            eval_metrics = trainer.evaluate()

            # ================================
            # 4) ëª¨ë¸ ì €ì¥ (ë¡œì»¬ ê²½ë¡œ)
            # ================================
            save_dir = output_dir + "/final"
            os.makedirs(save_dir, exist_ok=True)
            model.save_pretrained(save_dir)
            tokenizer.save_pretrained(save_dir)

            # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” save_dirì„ GCS/S3 ë“±ì— ì—…ë¡œë“œ í›„ ê·¸ ê²½ë¡œë¥¼ ì‚¬ìš©
            model_path = f"gs://models/{req.taskType.lower()}/{req.jobId}"
            metrics = {
                "accuracy": float(eval_metrics.get("eval_accuracy", 0.0)),
                "f1": float(eval_metrics.get("eval_f1", 0.0)),
                "loss": float(eval_metrics.get("eval_loss", 0.0)),
            }

        else:
            # ABSA ë° ê¸°íƒ€ íƒœìŠ¤í¬ëŠ” í˜„ì¬ ì‹œë®¬ë ˆì´ì…˜ë§Œ ì œê³µ
            time.sleep(5)
            model_path = f"gs://models/{req.taskType.lower()}/{req.jobId}"
            metrics = {"accuracy": 0.95, "loss": 0.1}

        payload = {
            "jobId": req.jobId,
            "status": "COMPLETED",
            "metrics": metrics,
            "modelPath": model_path,
            "errorMessage": None,
        }
    except Exception as e:
        print(f"[TRAIN] jobId={req.jobId} failed: {e}")
        payload = {
            "jobId": req.jobId,
            "status": "FAILED",
            "metrics": None,
            "modelPath": None,
            "errorMessage": str(e),
        }

    try:
        resp = requests.post(req.callbackUrl, json=payload, timeout=10)
        print(f"[TRAIN] callback to {req.callbackUrl} status={resp.status_code}")
    except Exception as e:
        print(f"[TRAIN] callback failed: {e}")


@app.post("/train", dependencies=[Depends(verify_api_key)])
async def start_training(req: TrainRequest, background_tasks: BackgroundTasks):
    """í•™ìŠµ ì‘ì—…ì„ ì‹œì‘í•˜ê³  ì¦‰ì‹œ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    background_tasks.add_task(run_training_job, req)
    return {"jobId": req.jobId, "status": "QUEUED"}

# ==========================================
# ì„œë²„ ì‹¤í–‰
# ==========================================
if __name__ == "__main__":
    # Ngrok ì„¤ì •
    print("Ngrok í„°ë„ì„ ì—½ë‹ˆë‹¤...")
    try:
        # ê¸°ì¡´ í„°ë„ì´ ìˆë‹¤ë©´ ë‹«ê¸° (ì¬ì‹¤í–‰ ì‹œ ì¶©ëŒ ë°©ì§€)
        ngrok.kill()
        
        # í¬íŠ¸ 8000ì„ ì™¸ë¶€ë¡œ ë…¸ì¶œ
        public_url = ngrok.connect(PORT).public_url
        print(f"\nğŸš€ Server is running!")
        print(f"ğŸŒ Public URL: {public_url}")
        print(f"ğŸ”‘ API Key: {API_KEY}")
        print(f"ğŸ“„ Docs: {public_url}/docs\n")
        
        # Uvicorn ì„œë²„ ì‹¤í–‰
        uvicorn.run(app, host="0.0.0.0", port=PORT)
        
    except Exception as e:
        print(f"âŒ ì„œë²„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")